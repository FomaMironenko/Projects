{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use after prepare_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fills the artists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    sys.path.insert(0, \"/usr/lib/python3.7/site-packages\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath  = \"arts.csv\"\n",
    "outpath = \"artsnew.csv\"\n",
    "df = pd.read_csv(inpath)\n",
    "del(df[\"Unnamed: 0\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns artist name from the line of dataset\n",
    "def get_artist(row: pd.Series):\n",
    "    return row[0].strip().rstrip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\" \", \"-\")\n",
    "\n",
    "# returns art name from the line of dataset\n",
    "def get_art(row: pd.Series):\n",
    "    return row[1].strip().rstrip().lower().replace(\".\", \"\").replace(\",\", \"\").replace(\" \", \"-\")\n",
    "\n",
    "# makes URL with artist and art names\n",
    "def url(artist: str, art: str):\n",
    "    return 'https://www.christies.com/lotfinder/' \\\n",
    "           'searchresults.aspx?sc_lang=eng&lid=1&searchFrom=searchresults&entry={}-' \\\n",
    "           '{}&searchtype=p&action=search'.format(artist, art)\n",
    "\n",
    "# parces search results on Christies, searching for most fitting variant\n",
    "def get_correct_url(s: requests.Session, artist: str, art: str):\n",
    "    page = s.get(url(artist, art), headers={\"User-Agent\": UserAgent().random})\n",
    "    text = BeautifulSoup(page.text, \"html.parser\")\n",
    "    batch = text.find_all(attrs={\"class\": \"image-container\"})\n",
    "    dist: float = 0; tmpdist: float = 0\n",
    "    URL: str = \"\"\n",
    "    tmpname: str = \"\"\n",
    "    tmpartist: str = \"\"\n",
    "    for var in batch:\n",
    "        try:\n",
    "            tmpname = var.find(\"h3\").get_text().strip().rstrip().lower()\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        l = str(var).find('alt=\"') + 5\n",
    "        tmpartist = str(var)[l: str(var).find(\"(\")].strip().rstrip().lower()\n",
    "        tmpdist = SequenceMatcher(None, art, tmpname).ratio()\n",
    "        artistdist = SequenceMatcher(None, artist, tmpartist).ratio()\n",
    "        if(artistdist >= 0.7 and tmpdist > dist):\n",
    "            dist = tmpdist\n",
    "            l = str(var).find('href=\"') + 6\n",
    "            URL  = str(var)[l: str(var).find('\">', l)]\n",
    "    URL = URL.replace(\"amp;\", \"\")\n",
    "    if(URL == \"\" and dist < 0.3):\n",
    "        return None\n",
    "    return URL\n",
    "\n",
    "# when the corresponding url is found by get_correct_url, \n",
    "# parces information from the page\n",
    "def parce(s: requests.Session, URL: str):\n",
    "    page = s.get(URL)\n",
    "    tmp = [\"\", \"\", \"\"]\n",
    "    text = BeautifulSoup(page.text, \"html.parser\")\n",
    "    estimate = text.find(attrs = {\"id\": \"main_center_0_lblPriceEstimatedPrimary\"})\n",
    "    description = text.find(attrs = {\"id\": \"main_center_0_lblLotDescription\"})\n",
    "    provenance = text.find(attrs = {\"id\": \"main_center_0_lblLotProvenance\"})\n",
    "    if(estimate != None):\n",
    "        tmp[0] = estimate.get_text()\n",
    "    if(description != None):\n",
    "        tmp[1] = description.get_text()\n",
    "    if(provenance != None):\n",
    "        tmp[2] = provenance.get_text()\n",
    "    return tmp\n",
    "\n",
    "# fills df[st:en] with data got by parce for each line\n",
    "# st - start index, en - end index\n",
    "def process(st: int, en: int, s: requests.Session, df: pd.DataFrame):\n",
    "    arr = []\n",
    "    artist: str\n",
    "    atr: str\n",
    "    for i, row in df.iloc[st:en].iterrows():\n",
    "        print(\"\\r                     \", end=\"\")\n",
    "        print(\"\\r\" + str(i) + \"/\" + \"[\" + str(st) + \":\" + str(en) + \"]\", end=\"\")\n",
    "        try:\n",
    "            artist = get_artist(row)\n",
    "            art    = get_art(row)\n",
    "        except AttributeError:\n",
    "            arr += [[\"\", \"\", \"\"]]\n",
    "            continue\n",
    "        URL = get_correct_url(s, artist, art)\n",
    "        if(URL != None):\n",
    "            tmp = parce(s, URL)\n",
    "            arr += [tmp]\n",
    "        else:\n",
    "            arr += [[\"\", \"\", \"\"]]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset processing takes pretty much time, so we divide it into parts\\nand process it by blocks of 50 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "s.mount(\"https://\", HTTPAdapter(max_retries=Retry(connect=3, backoff_factor=0.5)))\n",
    "page = s.get(url(get_artist(df.iloc[1]), get_art(df.iloc[1])), headers={\"User-Agent\": UserAgent().random})\n",
    "\n",
    "df[\"Estimate\"] = [\"\" for i in range(df.shape[0])]\n",
    "df[\"Description\"] = [\"\" for i in range(df.shape[0])]\n",
    "df[\"Provenance\"] = [\"\" for i in range(df.shape[0])]\n",
    "\n",
    "for i in range(0, 20):\n",
    "    arr = process(50*i, 50*(i + 1), s, df)\n",
    "    df[\"Estimate\"][50*i: 50*(i + 1)] = [x[0] for x in arr]\n",
    "    df[\"Description\"][50*i: 50*(i + 1)] = [x[1] for x in arr]\n",
    "    df[\"Provenance\"][50*i: 50*(i + 1)] = [x[2] for x in arr]\n",
    "    df.to_csv(outpath)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
